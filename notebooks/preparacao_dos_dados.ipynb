{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60582dd1884d1289",
   "metadata": {},
   "source": [
    "## Fase 3: Preparação dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4bb90a1e9c901d",
   "metadata": {},
   "source": [
    "### Importações de bibliotecas e carregamento dos dados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74e449c285794e99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T00:09:07.923011Z",
     "start_time": "2025-09-05T00:09:07.725112Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Rafael\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importações\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f317ff48c7f8f761",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T00:09:08.010817Z",
     "start_time": "2025-09-05T00:09:07.990701Z"
    }
   },
   "outputs": [],
   "source": [
    "# Carregar dataset bruto\n",
    "file_path = '../data/raw/desafio_indicium_imdb.csv'\n",
    "df = pd.read_csv(file_path, index_col=0) # essa coluna é irrelevante pra análise pois é apenas um índice sequencial\n",
    "\n",
    "# uma copia do dataset pra não alterar original\n",
    "data = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeaa34e71936c8c7",
   "metadata": {},
   "source": [
    "### Limpeza de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bd1c9a8fbcec2dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T00:09:08.080813Z",
     "start_time": "2025-09-05T00:09:08.067840Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series_Title       0\n",
      "Released_Year      0\n",
      "Certificate      101\n",
      "Runtime            0\n",
      "Genre              0\n",
      "IMDB_Rating        0\n",
      "Overview           0\n",
      "Meta_score       157\n",
      "Director           0\n",
      "Star1              0\n",
      "Star2              0\n",
      "Star3              0\n",
      "Star4              0\n",
      "No_of_Votes        0\n",
      "Gross            169\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# tratando valores ausentes\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Estratégias usadas:\n",
    "\"\"\"\n",
    "manter certificate como 'Unknown'\n",
    "preencher meta score com mediana\n",
    "em Gross é melhor remover os filmes sem informação, pois é uma métrica crítica\n",
    "\"\"\"\n",
    "\n",
    "data['Certificate'] = data['Certificate'].fillna(\"Unknown\")\n",
    "data['Meta_score'] = data['Meta_score'].fillna(data['Meta_score'].median())\n",
    "data = data.dropna(subset=['Gross'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8e69642ac4d9c9",
   "metadata": {},
   "source": [
    "### Meta_score → versão com média"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e533497e94940bc8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T00:09:08.153064Z",
     "start_time": "2025-09-05T00:09:08.144064Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores ausentes (versão com média):\n",
      "Series_Title     0\n",
      "Released_Year    0\n",
      "Certificate      0\n",
      "Runtime          0\n",
      "Genre            0\n",
      "IMDB_Rating      0\n",
      "Overview         0\n",
      "Meta_score       0\n",
      "Director         0\n",
      "Star1            0\n",
      "Star2            0\n",
      "Star3            0\n",
      "Star4            0\n",
      "No_of_Votes      0\n",
      "Gross            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Criar versão alternativa do dataset com Meta_score preenchido pela média\n",
    "data_mean = df.copy()\n",
    "data_mean['Certificate'] = data_mean['Certificate'].fillna(\"Unknown\")\n",
    "data_mean['Meta_score'] = data_mean['Meta_score'].fillna(data_mean['Meta_score'].mean())\n",
    "data_mean = data_mean.dropna(subset=['Gross'])\n",
    "\n",
    "print(\"Valores ausentes (versão com média):\")\n",
    "print(data_mean.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f17c91b25fb0c364",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T00:09:08.225194Z",
     "start_time": "2025-09-05T00:09:08.215805Z"
    }
   },
   "outputs": [],
   "source": [
    "# Correção dos tipos de dados\n",
    "\n",
    "# Runtime: extrair apenas os números e converter\n",
    "data['Runtime'] = (\n",
    "    data['Runtime']\n",
    "    .astype(str)                       # garante string\n",
    "    .str.extract(r'(\\d+)')[0]          # pega só os números\n",
    "    .astype(float)\n",
    "    .astype(\"Int64\")                   # int compatível com NaN\n",
    ")\n",
    "\n",
    "# Gross: remover vírgulas e converter para float\n",
    "data['Gross'] = (\n",
    "    data['Gross']\n",
    "    .astype(str)\n",
    "    .str.replace(\",\", \"\", regex=False)\n",
    "    .astype(float)\n",
    ")\n",
    "\n",
    "# Released_Year: garantir que seja numérico\n",
    "data['Released_Year'] = pd.to_numeric(data['Released_Year'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93c0dc4115d71f4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T00:09:08.272902Z",
     "start_time": "2025-09-05T00:09:08.269783Z"
    }
   },
   "outputs": [],
   "source": [
    "# remoção da coluna 'Unnamed: 0'\n",
    "if 'Unnamed: 0' in data.columns:\n",
    "    data = data.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481ed5ac132b5e21",
   "metadata": {},
   "source": [
    "### Engenharia de Variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eda35fd3c08e8c89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T00:09:08.332618Z",
     "start_time": "2025-09-05T00:09:08.325113Z"
    }
   },
   "outputs": [],
   "source": [
    "# Gênero Principal\n",
    "data['Main_Genre'] = data['Genre'].apply(lambda x: x.split(\",\")[0])\n",
    "\n",
    "# Dummies para gêneros principais\n",
    "genre_dummies = pd.get_dummies(data['Main_Genre'], prefix=\"Genre\")\n",
    "data = pd.concat([data, genre_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbe628bbfe850a08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T00:09:08.390314Z",
     "start_time": "2025-09-05T00:09:08.384819Z"
    }
   },
   "outputs": [],
   "source": [
    "# Popularidade de Diretor (Top 20)\n",
    "\n",
    "director_counts = data['Director'].value_counts()\n",
    "top_directors = director_counts.index[:20]\n",
    "data['Director_clean'] = data['Director'].apply(lambda x: x if x in top_directors else \"Other\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e10bef0995a6c044",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T00:09:08.451651Z",
     "start_time": "2025-09-05T00:09:08.441682Z"
    }
   },
   "outputs": [],
   "source": [
    "# Popularidade de Atores (Top 20)\n",
    "actors = pd.concat([data['Star1'], data['Star2'], data['Star3'], data['Star4']])\n",
    "actor_counts = actors.value_counts()\n",
    "top_actors = actor_counts.index[:20]\n",
    "for col in ['Star1', 'Star2', 'Star3', 'Star4']:\n",
    "    data[col] = data[col].apply(lambda x: x if x in top_actors else \"Other\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2fb9b13830c399d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T00:09:08.507741Z",
     "start_time": "2025-09-05T00:09:08.503738Z"
    }
   },
   "outputs": [],
   "source": [
    "# Idade do Filme\n",
    "current_year = 2025\n",
    "data['Movie_Age'] = current_year - data['Released_Year']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c97d4ab5481dcf7",
   "metadata": {},
   "source": [
    "### Preparação de Texto (Overview)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bf36e82347803f",
   "metadata": {},
   "source": [
    "#### Redução de dimensionalidade no TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7b8beeff19e158f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T00:09:08.572321Z",
     "start_time": "2025-09-05T00:09:08.561293Z"
    }
   },
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)\n",
    "    text = \" \".join([word for word in text.split() if word not in stop_words])\n",
    "    return text\n",
    "\n",
    "data['Overview_clean'] = data['Overview'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4cdcbe208b4ba664",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T00:09:08.650062Z",
     "start_time": "2025-09-05T00:09:08.625031Z"
    }
   },
   "outputs": [],
   "source": [
    "# Vetorização TF-IDF\n",
    "tfidf = TfidfVectorizer(max_features=500)\n",
    "overview_tfidf = tfidf.fit_transform(data['Overview_clean'])\n",
    "\n",
    "# transformação para dataframe\n",
    "overview_tfidf_df = pd.DataFrame(overview_tfidf.toarray(), columns=tfidf.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538d757b0cc9afaa",
   "metadata": {},
   "source": [
    "### TF-IDF original + SVD (versões separadas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47fbe13e3ea28b84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T00:09:08.788750Z",
     "start_time": "2025-09-05T00:09:08.702543Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensão TF-IDF original: 500\n",
      "Dimensão reduzida com SVD: 100\n"
     ]
    }
   ],
   "source": [
    "# Dataset com TF-IDF original - o de 500 features\n",
    "data_tfidf = pd.concat([data.reset_index(drop=True), overview_tfidf_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Dataset com SVD reduzido (100 features)\n",
    "svd = TruncatedSVD(n_components=100, random_state=42)\n",
    "overview_svd = svd.fit_transform(overview_tfidf)\n",
    "overview_svd_df = pd.DataFrame(overview_svd, columns=[f\"svd_{i}\" for i in range(1, 101)])\n",
    "data_svd = pd.concat([data.reset_index(drop=True), overview_svd_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "print(\"Dimensão TF-IDF original:\", overview_tfidf_df.shape[1])\n",
    "print(\"Dimensão reduzida com SVD:\", overview_svd_df.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7ce15c12b6c86b",
   "metadata": {},
   "source": [
    "### Multi-label One-Hot Encoding para coluna Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "682e97935e8570a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T00:09:08.869859Z",
     "start_time": "2025-09-05T00:09:08.853859Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de colunas de gênero criadas: 33\n"
     ]
    }
   ],
   "source": [
    "genre_dummies_full = data['Genre'].str.get_dummies(sep=\",\")\n",
    "\n",
    "# Remover espaços extras nos nomes das colunas\n",
    "genre_dummies_full.columns = genre_dummies_full.columns.str.strip()\n",
    "\n",
    "# Concatenar ao dataset base\n",
    "data = pd.concat([data, genre_dummies_full], axis=1)\n",
    "\n",
    "print(\"Total de colunas de gênero criadas:\", genre_dummies_full.shape[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f4d8665e53b6b4",
   "metadata": {},
   "source": [
    "### Escalonamento de variáveis numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f94e562168618c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T00:09:08.946314Z",
     "start_time": "2025-09-05T00:09:08.933020Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemplo de valores escalonados:\n",
      "      Gross  No_of_Votes   Runtime  Movie_Age  Meta_score\n",
      "1  0.609468     3.887505  1.852863   1.036420    1.885361\n",
      "2  4.253417     5.917729  1.016329  -0.665887    0.538240\n",
      "3 -0.098254     2.429453  2.834881   0.941847    1.043410\n",
      "4 -0.580661     1.120972 -1.020448   1.745714    1.548581\n",
      "5  2.822667     3.954076  2.798510  -0.429455    1.380190\n"
     ]
    }
   ],
   "source": [
    "numeric_cols = ['Gross', 'No_of_Votes', 'Runtime', 'Movie_Age', 'Meta_score']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "data_scaled = data.copy()\n",
    "data_scaled[numeric_cols] = scaler.fit_transform(data[numeric_cols])\n",
    "\n",
    "print(\"Exemplo de valores escalonados:\")\n",
    "print(data_scaled[numeric_cols].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94dc4216016865cf",
   "metadata": {},
   "source": [
    "### Ordem das features e salvar features.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30444bc0f51f4918",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T00:12:24.348735Z",
     "start_time": "2025-09-05T00:12:24.329372Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lista de features salva em ../data/processed/features.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# colunas duplicadas - remover\n",
    "data = data.loc[:, ~data.columns.duplicated()]\n",
    "data_tfidf = data_tfidf.loc[:, ~data_tfidf.columns.duplicated()]\n",
    "data_svd = data_svd.loc[:, ~data_svd.columns.duplicated()]\n",
    "data_scaled = data_scaled.loc[:, ~data_scaled.columns.duplicated()]\n",
    "\n",
    "# Reindexar em ordem alfabética\n",
    "data = data.reindex(sorted(data.columns), axis=1)\n",
    "data_tfidf = data_tfidf.reindex(sorted(data_tfidf.columns), axis=1)\n",
    "data_svd = data_svd.reindex(sorted(data_svd.columns), axis=1)\n",
    "data_scaled = data_scaled.reindex(sorted(data_scaled.columns), axis=1)\n",
    "\n",
    "# Salvar lista de features\n",
    "features = {\n",
    "    \"data\": list(data.columns),\n",
    "    \"data_tfidf\": list(data_tfidf.columns),\n",
    "    \"data_svd\": list(data_svd.columns),\n",
    "    \"data_scaled\": list(data_scaled.columns)\n",
    "}\n",
    "\n",
    "with open(\"../data/processed/features.json\", \"w\") as f:\n",
    "    json.dump(features, f, indent=4)\n",
    "\n",
    "print(\"Lista de features salva em ../data/processed/features.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed96d7d5992634e",
   "metadata": {},
   "source": [
    "### Salvar dataset processado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e3467c7600380de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T00:12:30.212157Z",
     "start_time": "2025-09-05T00:12:29.837990Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset base salvo em ../data/processed/imdb_clean.csv (bom para árvores)\n",
      "Dataset escalonado salvo em ../data/processed/imdb_clean_scaled.csv (bom para lineares/redes)\n",
      "Dataset TF-IDF salvo em ../data/processed/imdb_clean_tfidf.csv\n",
      "Dataset SVD salvo em ../data/processed/imdb_clean_svd.csv\n",
      "Dataset alternativo salvo em ../data/processed/imdb_clean_mean.csv (Meta_score = média)\n"
     ]
    }
   ],
   "source": [
    "# Salvar datasets processados\n",
    "\n",
    "output_path = '../data/processed/imdb_clean.csv'\n",
    "data.to_csv(output_path, index=False)\n",
    "print(f\"Dataset base salvo em {output_path} (bom para árvores)\")\n",
    "\n",
    "output_path_scaled = '../data/processed/imdb_clean_scaled.csv'\n",
    "data_scaled.to_csv(output_path_scaled, index=False)\n",
    "print(f\"Dataset escalonado salvo em {output_path_scaled} (bom para lineares/redes)\")\n",
    "\n",
    "output_path_tfidf = '../data/processed/imdb_clean_tfidf.csv'\n",
    "data_tfidf.to_csv(output_path_tfidf, index=False)\n",
    "print(f\"Dataset TF-IDF salvo em {output_path_tfidf}\")\n",
    "\n",
    "output_path_svd = '../data/processed/imdb_clean_svd.csv'\n",
    "data_svd.to_csv(output_path_svd, index=False)\n",
    "print(f\"Dataset SVD salvo em {output_path_svd}\")\n",
    "\n",
    "output_path_mean = '../data/processed/imdb_clean_mean.csv'\n",
    "data_mean.to_csv(output_path_mean, index=False)\n",
    "print(f\"Dataset alternativo salvo em {output_path_mean} (Meta_score = média)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
